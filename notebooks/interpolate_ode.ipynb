{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394443f2-36bb-4ffd-a384-54f5493c536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e58bd7-2094-4620-a504-cb53783c5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['BASE_PATH'] = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770cdf47-2e96-47ba-8f6d-fc5bdf67bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch import FloatTensor, Tensor, LongTensor\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from typing import Dict, List, Optional, Union, Tuple\n",
    "\n",
    "from lightning import seed_everything, Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.strategies.ddp import DDPStrategy\n",
    "from glob import glob\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from diffusion import Config\n",
    "import diffusion\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672bc694-5989-40e8-9e9b-ddc358da4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.dynamics import SDE, RSDE, EulerSolver\n",
    "from diffusion.utils import calc_model_grads_norm, calc_model_weights_norm, filter_losses\n",
    "from diffusion.models.contextual_denoising.modeling_clean_encoder import T5EncoderModel\n",
    "from diffusion.models.contextual_denoising.modeling_noisy_encoder import BertLMHeadModel\n",
    "from diffusion.models.contextual_denoising.score_estimator import ScoreEstimator\n",
    "from diffusion.models.contextual_denoising.typings import EncoderOutput\n",
    "\n",
    "from diffusion.helper import LinearWarmupLR\n",
    "from diffusion.dataset import EncNormalizer, enc_normalizer\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ae91b6-2840-42eb-b043-5574b8f47559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(exp_folder: str, ckpt_num: int, use_ema: bool = True):\n",
    "    seed_everything(1337, workers=True)\n",
    "\n",
    "    cfg = OmegaConf.load(osp.join(exp_folder, 'config.yaml'))\n",
    "    cfg.lightning_wrapper.sde_cfg.ode_sampling = True\n",
    "    cfg.datamodule.valid_dataloader_cfg.batch_size = 512\n",
    "    yaml_cfg = OmegaConf.to_yaml(cfg)\n",
    "    #print(yaml_cfg)\n",
    "    print(osp.abspath('.'))\n",
    "\n",
    "    wrapped_model = instantiate(cfg.lightning_wrapper, _recursive_=False)\n",
    "    ckpt_path = osp.join(exp_folder, f'step_{ckpt_num}.ckpt')\n",
    "    print(f'ckpt_path={ckpt_path}')\n",
    "    ckpt = torch.load(\n",
    "        ckpt_path,\n",
    "        map_location='cpu'\n",
    "    )\n",
    "    wrapped_model.load_state_dict(\n",
    "        ckpt['state_dict'],\n",
    "        strict=True\n",
    "    )\n",
    "    prefix_folder = 'ema_' if use_ema else ''\n",
    "    if use_ema:\n",
    "        from torch_ema import ExponentialMovingAverage\n",
    "        ema = ExponentialMovingAverage(wrapped_model.parameters(), 0)\n",
    "        ema.load_state_dict(\n",
    "            ckpt['callbacks']['EMACallback']\n",
    "        )\n",
    "        ema.copy_to(wrapped_model.parameters())\n",
    "    #wrapped_model.score_estimator.load_state_dict(\n",
    "    #    torch.load('score_estimator.pth', map_location='cpu')\n",
    "    #)\n",
    "    wrapped_model.eval()\n",
    "    return wrapped_model, cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b5ff43-b9cc-4bbb-b50e-d284003e8f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tbadmaev/cls_glue_diff/light_diffusion/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['enc_normalizer.enc_mean', 'enc_normalizer.enc_std']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at t5-base were not used when initializing T5EncoderModel: ['decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.final_layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5EncoderModel were not initialized from the model checkpoint at t5-base and are newly initialized: ['enc_normalizer.enc_mean', 'enc_normalizer.enc_std']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTORED SLAVYAN\n",
      "ckpt_path=../experiments/wiki-pretrain-nam-noisy-067-bs512-t2/step_1000000.ckpt\n"
     ]
    }
   ],
   "source": [
    "wrapped_model, cfg = load_model('../experiments/wiki-pretrain-nam-noisy-067-bs512-t2', ckpt_num=1_000_000, use_ema=True)\n",
    "cfg: diffusion.Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d3ed28-e48e-4f7a-a15d-065152546dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"max_steps\": 1000000,\n",
      "    \"seed\": 0,\n",
      "    \"every_n_train_steps\": 50000,\n",
      "    \"grad_clip_norm\": 1.0,\n",
      "    \"project\": \"cross_attention\",\n",
      "    \"exp_name\": \"wiki-pretrain-nam-noisy-067-bs512-t2\",\n",
      "    \"pretrained_path\": null,\n",
      "    \"resume_path\": null,\n",
      "    \"max_epochs\": 50,\n",
      "    \"every_n_epochs\": 1,\n",
      "    \"precision\": \"bf16-mixed\",\n",
      "    \"lightning_wrapper\": {\n",
      "        \"optim_partial\": {\n",
      "            \"_target_\": \"torch.optim.AdamW\",\n",
      "            \"_partial_\": true,\n",
      "            \"lr\": 0.0002,\n",
      "            \"weight_decay\": 0.01,\n",
      "            \"betas\": [\n",
      "                0.9,\n",
      "                0.98\n",
      "            ],\n",
      "            \"eps\": 1e-06\n",
      "        },\n",
      "        \"sched_partial\": {\n",
      "            \"_target_\": \"diffusion.LinearWarmupLR\",\n",
      "            \"_partial_\": true,\n",
      "            \"warmup_steps\": 5000,\n",
      "            \"warmup_start_lr\": 1e-06\n",
      "        },\n",
      "        \"noisy_enc_normalizer_cfg\": {\n",
      "            \"_target_\": \"diffusion.EncNormalizer\",\n",
      "            \"enc_mean_path\": \"wiki_pret_old/encodings-bert_base-wiki-mean.pt\",\n",
      "            \"enc_std_path\": \"wiki_pret_old/encodings-bert_base-wiki-std.pt\"\n",
      "        },\n",
      "        \"clean_enc_normalizer_cfg\": {\n",
      "            \"_target_\": \"diffusion.EncNormalizer\",\n",
      "            \"enc_mean_path\": \"data/t5-base-stats/mean.pth\",\n",
      "            \"enc_std_path\": \"data/t5-base-stats/std.pth\"\n",
      "        },\n",
      "        \"_target_\": \"diffusion.lightning_wrappers.contextual_denoising.SlavaContextualDenoising\",\n",
      "        \"ce_coef\": 0.0,\n",
      "        \"sde_cfg\": {\n",
      "            \"_target_\": \"diffusion.dynamics.CosineSD\",\n",
      "            \"N\": 1000,\n",
      "            \"d\": 10,\n",
      "            \"prediction\": \"x_0\",\n",
      "            \"ode_sampling\": true\n",
      "        }\n",
      "    },\n",
      "    \"datamodule\": {\n",
      "        \"_target_\": \"diffusion.dataset.SimpleDataModule\",\n",
      "        \"_recursive_\": false,\n",
      "        \"train_dataset_cfg\": {\n",
      "            \"_target_\": \"diffusion.dataset.wiki_dataset.WikiDataset\",\n",
      "            \"max_length\": 64,\n",
      "            \"train\": true\n",
      "        },\n",
      "        \"valid_dataset_cfg\": {\n",
      "            \"_target_\": \"diffusion.dataset.wiki_dataset.WikiDataset\",\n",
      "            \"max_length\": 64,\n",
      "            \"train\": false\n",
      "        },\n",
      "        \"train_dataloader_cfg\": {\n",
      "            \"_target_\": \"torch.utils.data.DataLoader\",\n",
      "            \"batch_size\": 512,\n",
      "            \"num_workers\": 16,\n",
      "            \"drop_last\": true,\n",
      "            \"shuffle\": true\n",
      "        },\n",
      "        \"valid_dataloader_cfg\": {\n",
      "            \"_target_\": \"torch.utils.data.DataLoader\",\n",
      "            \"batch_size\": 512,\n",
      "            \"num_workers\": \"${datamodule.train_dataloader_cfg.num_workers}\",\n",
      "            \"drop_last\": false,\n",
      "            \"shuffle\": false\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(OmegaConf.to_container(cfg), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd24c40c-38c4-4dd9-b2f6-98242ef9be50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbadmaev/new_conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Found cached dataset parquet (/home/tbadmaev/.cache/huggingface/datasets/Graphcore___parquet/Graphcore--wikipedia-bert-128-d489528ddee484b2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached split indices for dataset at /home/tbadmaev/.cache/huggingface/datasets/Graphcore___parquet/Graphcore--wikipedia-bert-128-d489528ddee484b2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-0bcf1810a390dc82.arrow and /home/tbadmaev/.cache/huggingface/datasets/Graphcore___parquet/Graphcore--wikipedia-bert-128-d489528ddee484b2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-4395827f851c38ac.arrow\n",
      "/home/tbadmaev/new_conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Found cached dataset parquet (/home/tbadmaev/.cache/huggingface/datasets/Graphcore___parquet/Graphcore--wikipedia-bert-128-d489528ddee484b2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached split indices for dataset at /home/tbadmaev/.cache/huggingface/datasets/Graphcore___parquet/Graphcore--wikipedia-bert-128-d489528ddee484b2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-0bcf1810a390dc82.arrow and /home/tbadmaev/.cache/huggingface/datasets/Graphcore___parquet/Graphcore--wikipedia-bert-128-d489528ddee484b2/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-4395827f851c38ac.arrow\n"
     ]
    }
   ],
   "source": [
    "datamodule: diffusion.SimpleDataModule = instantiate(cfg.datamodule, _recursive_=False)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a406fa20-1e03-4ff6-ac91-0124b531d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbadmaev/new_conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2b8ebc873880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader: DataLoader = datamodule.val_dataloader()[0]\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76fac78e-e3c2-491c-ab81-57d2f3eda382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbadmaev/new_conda/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['clean_input_ids', 'clean_attention_mask', 'noisy_input_ids', 'noisy_token_type_ids', 'noisy_attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n",
    "iterator_loader = iter(loader)\n",
    "batch = next(iterator_loader)\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63af7443-e7dc-4e04-ae00-5f1154566669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.utils import dict_to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514b873c-22bc-4a94-b19b-13339dbfc4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SlavaContextualDenoising(\n",
       "  (noisy_part_encoder): BertLMHeadModel(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (enc_normalizer): EncNormalizer()\n",
       "  )\n",
       "  (clean_part_encoder): T5EncoderModel(\n",
       "    (shared): Embedding(32128, 768)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-11): 11 x T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseActDense(\n",
       "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (act): ReLU()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (enc_normalizer): EncNormalizer()\n",
       "  )\n",
       "  (score_estimator): SlavaEstimator(\n",
       "    (time_emb): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1536, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    )\n",
       "    (encoder): TransformerEncoder(\n",
       "      (input_blocks): ModuleList(\n",
       "        (0-5): 6 x BertBlock(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (output_blocks): ModuleList(\n",
       "        (0-5): 6 x BertBlock(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (time_layers): ModuleList(\n",
       "        (0-11): 12 x Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = dict_to_device(batch, device)\n",
    "wrapped_model.to(device)\n",
    "latent_ode_encs = torch.load('latent_ode_encs.pth', map_location='cpu').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3241b8c-ef69-434b-b428-f9e6c5d01ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def ode_cycle_forward(batch: Dict[str, Tensor]):\n",
    "    wrapped_model.eval()\n",
    "    assert wrapped_model.solver.rsde.ode_sampling is True, \"Not ODE sampling\"\n",
    "    \n",
    "    to_clean_part, to_noise_part = wrapped_model.split_batch(batch)\n",
    "    clean_part: EncoderOutput = wrapped_model.clean_part_encoder.forward(**to_clean_part)\n",
    "    noisy_part: EncoderOutput = wrapped_model.noisy_part_encoder.forward(**to_noise_part)\n",
    "    \n",
    "    noisy_part_attention_mask = torch.ones_like(\n",
    "        batch['noisy_attention_mask']\n",
    "    )\n",
    "    \n",
    "    shape = noisy_part_attention_mask.shape + (clean_part.normed.shape[-1],)\n",
    "    cross_encodings = clean_part.normed\n",
    "    \n",
    "    target_encodings = noisy_part.normed\n",
    "    \n",
    "    cross_attention_mask = to_clean_part['attention_mask']\n",
    "    attn_mask = noisy_part_attention_mask\n",
    "\n",
    "    score_call = partial(\n",
    "        wrapped_model.score_estimator.forward,\n",
    "        cross_attention_mask=cross_attention_mask,\n",
    "        cross_encodings=cross_encodings\n",
    "    )\n",
    "    verbose = True\n",
    "    with torch.no_grad():\n",
    "        x_t = target_encodings\n",
    "\n",
    "        timesteps = torch.linspace(\n",
    "            wrapped_model.sde.T / wrapped_model.sde.N,\n",
    "            wrapped_model.sde.T,\n",
    "            wrapped_model.sde.N,\n",
    "            device=device\n",
    "        )\n",
    "        rang = trange if verbose else range\n",
    "\n",
    "        for idx in rang(wrapped_model.sde.N):\n",
    "            t = timesteps[idx]\n",
    "            input_t = t * torch.ones(shape[0], device=device)\n",
    "            \n",
    "            dt = 1. / wrapped_model.sde.N\n",
    "            \n",
    "            rsde_params = wrapped_model.solver.rsde.sde(score_call, x_t, input_t, attn_mask)\n",
    "            \n",
    "            drift = rsde_params['drift']\n",
    "            # return rsde_params\n",
    "            \n",
    "            x_t = x_t + drift * dt\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc0e53-47a7-48b2-aa31-68aa2513ad20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d1eb75049246f6a4beae84c95390e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_ode_encs = ode_cycle_forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3479ba-4de7-48dc-8a9f-0f7b2c68ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_ode_encs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462564d1-ee1a-48ea-a540-f437bf5e65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(latent_ode_encs.cpu(), 'latent_ode_encs.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b4100c-177d-48b6-a56f-a17772b5bae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85930e-c5c4-4d84-a7fe-bc674152d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c66d0c-97de-43d3-9469-b2969995ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_ode_encs = torch.load('latent_ode_encs.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a033f-5753-4a8b-a2de-46a7c3e8f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_ode_encs = latent_ode_encs.cpu().numpy()\n",
    "latent_ode_encs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fe782-64a3-4c48-90b9-f28d27249fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coord_distrib(coord_idx: int):\n",
    "    obs = latent_ode_encs.reshape(-1, 768)[:, coord_idx]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    counts, bins = np.histogram(obs, bins=100)\n",
    "    plt.stairs(counts / obs.shape[0], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bf941-f56f-44f0-abb2-a9637a43c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coord_distrib(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160fc9d0-0783-40a4-991d-a24b7efacd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [new_conda]",
   "language": "python",
   "name": "conda-env-new_conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
