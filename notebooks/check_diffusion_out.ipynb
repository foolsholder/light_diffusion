{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbadmaev/new_conda/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diffusion\n",
    "from diffusion.models import BertLMHeadModel as OurMaskedAttentionBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.models.score_estimator import ScoreEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertLMHeadModel\n",
    "\n",
    "bert_conf = BertConfig('bert-base-uncased')\n",
    "score_estimator = ScoreEstimator(bert_conf)\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "ema = ExponentialMovingAverage(score_estimator.parameters(), 0)\n",
    "\n",
    "ckpt = torch.load('../experiments/ce_masked/step=10000.ckpt', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tried to `load_state_dict()` with the wrong number of parameters in the saved state.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ema\u001b[39m.\u001b[39;49mload_state_dict(ckpt[\u001b[39m'\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mEMACallback\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m st_dict \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(ckpt[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])()\n\u001b[1;32m      3\u001b[0m patt \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mscore_estimator\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/new_conda/lib/python3.10/site-packages/torch_ema/ema.py:298\u001b[0m, in \u001b[0;36mExponentialMovingAverage.load_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollected_params[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollected_params[i]\u001b[39m.\u001b[39mto(\n\u001b[1;32m    295\u001b[0m                     device\u001b[39m=\u001b[39mp\u001b[39m.\u001b[39mdevice, dtype\u001b[39m=\u001b[39mp\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    296\u001b[0m                 )\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    299\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTried to `load_state_dict()` with the wrong number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameters in the saved state.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to `load_state_dict()` with the wrong number of parameters in the saved state."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ema.load_state_dict(ckpt['callbacks']['EMACallback'])\n",
    "st_dict = type(ckpt['state_dict'])()\n",
    "patt = 'score_estimator'\n",
    "for k, v in ckpt['state_dict'].items():\n",
    "    if patt in k:\n",
    "        st_dict[k[len(patt)+1:]] = v\n",
    "score_estimator.load_state_dict(st_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/tbadmaev/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Found cached dataset glue (/home/tbadmaev/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from diffusion.dataset.glue_data import SST2Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = SST2Dataset(train=True)\n",
    "valid_dataset = SST2Dataset(train=False)\n",
    "\n",
    "\n",
    "def get_val_loader():\n",
    "    return DataLoader(valid_dataset, batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "def get_train_loader():\n",
    "    return DataLoader(train_dataset, batch_size=256, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from diffusion.utils import dict_to_device\n",
    "\n",
    "\n",
    "def print_accuracy(loader, bert_model):\n",
    "    total_true_pred = 0\n",
    "    total_label_pred = 0\n",
    "    total_size = 0\n",
    "    total_word_count = 0\n",
    "\n",
    "    total_label_from_all = 0\n",
    "\n",
    "    bar = tqdm(loader)\n",
    "    for batch in bar:\n",
    "        batch = dict_to_device(batch, 'cuda')\n",
    "        count = torch.sum(batch['attention_mask'], dim=-1).long()\n",
    "        logits = bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask']).logits\n",
    "        # 0 - [CLS], 1 - label, count-1 - [SEP]\n",
    "        pred_label_from_all = torch.argmax(logits[:, 1], dim=-1)\n",
    "        labels_cat = batch['labels'].view(-1) * 2748 + (1 - batch['labels'].view(-1)) * 2053\n",
    "        total_label_from_all += torch.sum((pred_label_from_all == labels_cat).float())\n",
    "\n",
    "\n",
    "        pred_label_logits = logits[:, 1, [2053, 2748]]\n",
    "        pred_label = torch.argmax(pred_label_logits, dim=-1)\n",
    "        total_label_pred += torch.sum((pred_label == batch['labels'].view(-1)).float())\n",
    "        total_size += len(pred_label)\n",
    "\n",
    "        all_pred_ids = torch.argmax(logits, dim=-1)\n",
    "        correct = (all_pred_ids == batch['input_ids'])\n",
    "        total_word_count += torch.sum(count - 3)\n",
    "        for sent, end_idx in zip(correct, count):\n",
    "            total_true_pred += torch.sum(sent[2:end_idx])\n",
    "\n",
    "        bar.set_description(f'label_acc: {total_label_pred / total_size:.5f}, \\\n",
    "                            text_recon_acc: {total_true_pred / total_word_count:.5f}, \\\n",
    "                            label_acc_from_all: {total_label_from_all/ total_size:.5f}')\n",
    "\n",
    "    return total_label_pred / total_size, total_true_pred / total_word_count, total_label_from_all/ total_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Our masked attention bert on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f5562164574d229e5c976e0fdd65eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.6250, device='cuda:0'),\n",
       " tensor(0.9393, device='cuda:0'),\n",
       " tensor(0.2317, device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_accuracy(get_val_loader(), our_bert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default bert on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0255848d1f814481b8136daf49b802cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7110, device='cuda:0'),\n",
       " tensor(0.9455, device='cuda:0'),\n",
       " tensor(0.3567, device='cuda:0'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_accuracy(get_val_loader(), h_bert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Our masked attention bert on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264f62a7e6e44448865af6a1997ac66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7652, device='cuda:0'),\n",
       " tensor(0.8824, device='cuda:0'),\n",
       " tensor(0.3382, device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_accuracy(get_train_loader(), our_bert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default bert on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf80f305e2d4ddc8928c2619edf77d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8031, device='cuda:0'),\n",
       " tensor(0.8955, device='cuda:0'),\n",
       " tensor(0.4452, device='cuda:0'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_accuracy(get_train_loader(), h_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] no hide new secretions from the parental units [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] no contains no wit, only labored gags [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] yes that loves its characters and communicates something rather beautiful about human nature [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] no remains utterly satisfied to remain the same throughout [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
       " '[CLS] no on the worst revenge - of - the - nerds cliches the filmmakers could dredge up [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(get_train_loader()))\n",
    "batch = dict_to_device(batch, 'cuda')\n",
    "\n",
    "logits = h_bert(input_ids=batch['input_ids'], attention_mask=batch['attention_mask']).logits\n",
    "pred_ids = torch.argmax(logits, dim=-1)\n",
    "pred_label_from_all = torch.argmax(logits[:, 1], dim=-1)\n",
    "labels_cat = batch['labels'].view(-1) * 2748 + (1 - batch['labels'].view(-1)) * 2053\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "input_sent = tokenizer.batch_decode(batch['input_ids'])\n",
    "input_sent[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. no hide new secretions from the parental....... no no no.. no no... no no no new new or or the....... no no no.. no no new.. no no no no no no hide new itemsions from the other....... no',\n",
       " '... no wit, only labored gag....... no wit no no. no.... it no humor any nor and no wit. and. and... no. no. no no all and.. no no - it - much much wit nor only short short....... no',\n",
       " '.. that loves its characters and communicates something rather beautiful about human....... it it it.. it it... it it and communicate, and communicate of. its. and... it it it.. it it yes yes. it it loves its characters and communicate with something and deeply about....',\n",
       " '.. remains utterly satisfied to remain the same....... he no.... no... he he he,, and and,. forever.. forever.. he he he. he he.... he he he he he he,,, and and, forever...... he he',\n",
       " '. no on the worst revenge - of - the - nerds cliches the filmmakers could dr make....... no the the some. - - - the - - punk and movie and the ever could. ever..... no. no no the the the revenge revenge. - the - ne - cr story that the']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sent = tokenizer.batch_decode(pred_ids)\n",
    "pred_sent[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
